\documentclass{article}
\setcounter{section}{2}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[parfill]{parskip}

\begin{document}
\title{Sheldon Axler - Linear Algebra Done Right, 3rd edition - Chapter 3}
\author{Andrew Lim}

\def \problem#1{\subsubsection*{Problem #1}}
\def \real{\mathbf{R}}
\def \complex{\mathbf{C}}
\def \field{\mathbf{F}}

Notations are the same as what Axler uses. For example, we use boldface $\real$
for the reals, and $\field$ is $\real$ or $\complex$, not a general field.

\section{Linear Maps}

\subsection{The Vector Space of Linear Maps}

\problem{1}

$\Rightarrow$: $T(a(x,y,z)) = aT(x,y,z)$ only if $b = c = 0$.

$\Leftarrow$: if $b = c = 0$, then
\begin{align*}
  T(a(x,y,z)) & = (2ax - 4ay - 3az, 6ax) = aT(x,y,z) \\
  T(x_1 + x_2, y_1 + y_2, z_1 + z_2) & = (2(x_1 + x_2) - 4(y_1 + y_2) + 3(z_1 +
                                       z_2), 6(x_1 + x_2)) \\
              & = (2x_1 - 4y_1 + 3z_1, 6x_1) + (2x_2 - 4y_2 + 3z_2, 6x_2) \\
              & = T(x_1, y_1, z_1) + T(x_2, y_2, z_2)
\end{align*}

\problem{2}

$\Rightarrow$: Homogeneity requires $b = 0$, otherwise the $b$ term would
feature $\lambda^2$ for any $p$ where $p(1) \neq 0, p(2) \neq 0$. It also
requires $c = 0$, otherwise for any $p$ where $p(0) \neq 0$, we could pick
$\lambda$ such that $\sin (\lambda p(0)) \neq \lambda \sin (p(0))$.

$\Leftarrow$: if $b = c = 0$, then
\begin{align*}
  T(\lambda p) & = (3 \lambda p(4) + 5 \lambda p'(6) + \int_{-1}^2 x^3 \lambda p(x) dx) \\
               & = \lambda (3p(4) + 5p'(6), \int_{-1}^2 x^3 p(x) dx) \\
               & = \lambda Tp \\
  T(p + q) & = (3(p+q)(4) + 5(p+q)'(6), \int_{-1}^2 x^3(p+q)(x) dx) \\
               & = (3p(4) + 5p'(6) + 3q(4) + 5q'(6), \int_{-1}^2 x^3p(x) dx + \int_{-1}^2 x^3q(x) dx) \\
               & = Tp + Tq
\end{align*}

\problem{3}

Denote the standard basis vectors as $e_i$. Rewrite $(x_1, \ldots, x_n)$ as
$x_1e_1 + \ldots + x_ne_n$. Then, by the two conditions of linearity,
\begin{align*}
  T(x_1, \ldots, x_n) & = \sum_i^n x_iT(e_i)
\end{align*}

We can likewise write $T(e_i)$ in terms of basis vectors $e_i$ in $\field^m$. So
denote:
\begin{align*}
  T(e_i) & = \sum_j^m a_{ji}e_j
\end{align*}

Combining the two and reordering the summation terms, we get:
\begin{align*}
  T(x_1, \ldots, x_n) & = \sum_i^n x_i \sum_j^m a_{ji}e_j \\
                      & = \sum_j^m \sum_i^n a_{ji}x_ie_j
\end{align*}

which is what we want to show, since the last expression above amounts to
putting $a_{j1}x_1 + \ldots + a_{jn}x_n$ into the $j$th element of $T(x_1,
\ldots, x_n)$.

\problem{4}

If the $v_i$ were not linearly independent, then there would be some $a_i$ not
all 0 such that $\sum a_iv_i = 0$. But then $T(\sum a_iv_i) = \sum a_iT(v_i) =
T(0) = 0$, which violates LI of $T(v_i)$.

\problem{5}

Commutativity: $(S+T)(v) = Sv + Tv = Tv + Sv = (T+S)(v)$

Associativity: $(S+(T+U))(v) = Sv + (T+U)v = Sv + Tv + Uv = (S+T)v + Uv =
((S+T) + U(v))$

Additive identity: The zero map $Z(v) = 0$: $(S+Z)(v) = Sv + Zv = Sv = S(v)$.

Additive inverse: For a map $S$, pick inverse $T$ such that $T(v) = -S(v)$. This
is a linear map since $T(u+v) = -S(u+v) = -Su - Sv = T(u) + T(v)$, and since
$T(\lambda v) = -S(\lambda v) = -\lambda Sv = \lambda Tv$. And it is an additive
inverse, since $(S+T)(v) = S(v) + T(v) = 0$, so $S+T$ is the zero map.

Multiplicative identity: the scalar $1 \in \field$: $(1S)(v) = 1(Sv) = Sv$, so
$1S = S$.

Distributive: $(\lambda (S+T))(v) = \lambda ((S+T)(v)) = \lambda (Sv + Tv) =
\lambda Sv + \lambda Tv = (\lambda S)(v) + (\lambda T)(v)$.

\problem{6}

Associativity: $((T_1T_2)T_3)(v) = (T_1T_2)(T_3v) = T_1(T_2(T_3v)) =
T_1((T_2T_3)v) = (T_1(T_2T_3))(v)$.

Identity: $(TI)(v) = T(Iv) = Tv$. Also, $(IT)(v) = I(Tv) = Tv$.

Distributive: $((S_1 + S_2)T)(v) = (S_1 + S_2)(Tv) = S_1(Tv) + S_2T(v) =
(S_1T)(v) + (S_2T)(v)$. Also, $(S(T_1 + T_2))(v) = S((T_1 + T_2)(v)) = S(T_1v +
T_2v) = S(T_1v) + S(T_2v) = (ST_1)(v) + (ST_2)(v)$.

\problem{7}

Pick a basis of $V$, $\{v_1\}$. Then for any linear map $T$, for any $v \in V$
written as $v = av_1$, $T(v) = T(av_1) = aT(v_1)$. Since $T(v_1) \in V$, it can
also be written as $bv_1$ for some scalar $b$, so $T(v) = abv_1 = b(av_1) = bv$,
demonstrating that $T$ is scalar multiplication by $b$.

\problem{8}

Let $\varphi$ be the distance from the origin, taking a positive sign above the
x-axis and a negative sign below:
\begin{align*}
\varphi(x,y) & = \text{sgn}(y)\sqrt{x^2 + y^2}
\end{align*}

Then $\varphi(ax,ay) = a \varphi(x,y)$, but additivity is not satisfied, for
example $\varphi(1,0) + \varphi(0,1) = 1 + 1 = 2$, but $\varphi(1,1) =
\sqrt{2}$.

\problem{9}

\problem{10}

Pick $u$ such that $Su \neq 0$, and $v$ such that $v \notin U$. Then $u+v \notin
U$ either, since otherwise $v$ would be by closure and additive inverses. So
$T(u+v) = 0$. But $T(u) + T(v) = T(u) = S(u) \neq 0$. So $T$ does not satisfy
linearity.

\problem{11}

Consider a basis of $U$ $\{u_i\}$. Extend this to a basis of $V$ with vectors
$\{v_i\}$. Then define $T$ such that $T(u_i) = S(u_i)$ and $T(v_i) = 0$. For any
$u \in U$, clearly $Tu = Su$. We need to show that $T$ is a linear map.

For $v, w \in V$, let their representations in terms of the basis above be $a_i$
and $b_i$, respectively. Then $T(v+w) = T(\sum (a_i + b_i) u_i)$ over the $u_i$
basis vectors only, since the terms with the $v_i$ basis vectors get mapped to
0. This equals $S(\sum (a_i + b_i) u_i)$, since this vector is in $U$. Likewise,
$T(v) + T(w) = T(\sum a_iu_i) + T(\sum b_iu_i) = S(\sum a_iu_i) + S(\sum b_iu_i)
= S(\sum (a_i + b_i) u_i)$, with the last step by linearity of $S$. So $T$ has
additivity.

$T(\lambda v) = T(\lambda \sum a_iu_i) = S(\lambda \sum a_iu_i) = \lambda S(\sum
a_iu_i)$, and $\lambda T(v) = \lambda S(\sum a_iu_i)$, again by similar logic;
the parts of $v$ associated with the $v_i$ disappear, leaving only the parts
associated with $u_i$, which is in $U$ and which satisfy linearity by linearity
of $S$.

\problem{12}

Let $v_i$ be a basis for $V$. Consider some list of linear maps $T_1, \ldots,
T_n$. Then any linear combination of these takes the form $\sum \lambda_i T_i$,
which by linearity maps $v_1$ (the first basis vector of $V$, which must exist
since $\dim V > 0$) to $\lambda_i T_iv_1$.

Because $W$ is infinite-dimensional, the $T_iv_1$ must not span it, so we can
pick $w \in W, w \notin \text{span}(\{T_iv_1\})$. Then pick the linear map $T$
such that $Tv_1 = w$ and $Tv_i = 0$ for any $i > 1$. 3.5 assures us that this
map exists. It is not possible for any linear combination of the $T_i$ to map
$v_1$ to $w$ because we picked it outside the span of the $T_iv_1$. Hence, no
list of $T_i$ spans $\mathcal{L}(V,W)$, making it infinite-dimensional.

\problem{13}

By LD, there exist $a_i$ not all 0 such that $\sum a_iv_i = 0$. Then any linear
map $T$ must satisfy $\sum a_iTv_i = 0$.

For any $i$ where $a_i = 0$, pick $w_i = 0$. For any $i$ where $a_i \neq 0$,
pick $w_i = (1/a_i)w$ for some $w \neq 0$ (which is possible since $W \neq
\{0\}$). Then any linear map $T$ where $Tv_i = w_i$ would have to satisfy $\sum
a_iw_i = 0$, or $nw = 0$, where $n$ is the number of $a_i$ where $a_i \neq 0$.
$n > 0$ and $w \neq 0$, so this is impossible; hence no $T$ can satisfy $Tv_i =
w_i$ for this choice of $w_i$.

\problem{14}

Let $v_1, \ldots, v_n$ be a basis of $V$, with $n \geq 2$. Consider the two
maps:
\begin{align*}
  S(a_1v_1 + a_2v_2 + \ldots + a_nv_n) & = a_2v_1 + a_1v_2 \\
  T(a_1v_1 + a_2v_2 + \ldots + a_nv_n) & = a_1v_1
\end{align*}

In other words, both $S$ and $T$ zero out all but the terms for the first two
basis vectors, $S$ switches the coefficients of $v_1$ and $v_2$, and $T$
additionally zeroes out the coefficient of $v_2$.

These are both linear: clearly applying either to a sum or a scalar multiple
passes the coefficients and scaling factor onto their respective results. But:
\begin{align*}
  ST(a_1v_1 + a_2v_2) & = a_1v_2 \\
  TS(a_1v_1 + a_2v_2) & = a_2v_1
\end{align*}

\subsection{Null Spaces and Ranges}

\problem{1}

$T(x_1, \ldots, x_5) = (x_1, x_2)$. A basis for $\text{null}(T)$ is the
standard basis vectors $e_3, e_4, e_5$, and a basis for $\text{range}(T)$ is
$e_1, e_2$.

\problem{2}

For any $v \in V$, $(ST)^2(v) = S(T(S(T(v))))$, by associativity. $S(T(v)) \in
\text{range}(S)$, so $T(S(T(v))) = 0$, and so the whole thing is 0.

\problem{3a}

If the $v_i$ span $V$ then $T$ is surjective, just pass the coefficients of a
representation of any $v \in V$ as the arguments to $T$.

\problem{3b}

If the $v_i$ are LI then $T$ is injective. If $T(a_i) = T(b_i)$ then $\sum (a_i
- b_i)v_i = 0$, which by LI requires that $a_i - b_i = 0$, or $a_i = b_i$, for
all $i$.

\problem{4}

Consider $T_1(x_i) = (x_1, x_2, 0, 0)$ and $T_2(x_i) = (0, 0, x_3, x_4)$. The
null space of $T_i$ has a basis $e_1, e_2, e_5$, and the null space of $T_2$
is spanned by $e_3, e_4, e_5$, both dimension 3, so $T_1$ and $T_2$ are both
elements of this set. But $T_1 + T_2 = (x_1, x_2, x_3, x_4)$ has as the basis of
its null space only $e_5$, so it has dimension 1 and is not in this set. So the
set is not closed under addition.

\problem{5}

$T(x_i) = (x_3, x_4, 0, 0)$. The range has basis $e_1, e_2$. The null space
consists of any vectors with 0 as their third and fourth elements, so it also
has basis $e_1, e_2$, so $\text{null}(T) = \text{range}(T)$.

\problem{6}

For any $T$, by the Fundamental Theorem of Linear Maps, $\dim \text{null}(T) +
\dim \text{range}(T) = 5$, so it is not possible for the null space and range to
have the same dimension, and thus they cannot be equal.

\problem{7}

Pick a basis $v_i$ for $V$ and $w_i$ for $W$. Consider the map $T_1$ such that
$T_1(v_1) = 0$ but $T_1(v_i) = w_i$ for all other $i$ up to $\dim V$, and also
the map $T_2$ such that $T_2(v_2) = 0$ but $T_2(v_i) = w_i$ for all other $i$ up
to $\dim V$.

Neither $T_1$ nor $T_2$ is injective, because their null spaces are not $\{0\}$.
But $T_1 + T_2$ maps every $v_i$ to $w_i$, making its null space $\{0\}$, and so
$T_1 + T_2$ is injective, making this set not closed under addition.

\problem{8}

Same notations as problem 7.

Neither $T_1$ nor $T_2$ are surjective, because $\text{range}(T_1)$ does not
include $w_1$ and $\text{range}(T_2)$ does not include $w_2$. But $T_1 + T_2$
maps to every $w_i$ from some $v_i$, making it surjective, and so this set is
not closed under addition.

\problem{9}

Suppose $Tv_i$ were not LI. Then there would be some $a_i$ not all 0 satisfying
$\sum a_iTv_i = 0$. By linearity we would also have $T(\sum a_iv_i) = 0$.
Because $T$ is injective, its null space must be $\{0\}$, so $\sum a_iv_i = 0$,
but this violates the assumption that the $v_i$ are LI.

\end{document}