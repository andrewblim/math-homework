\documentclass{article}
\setcounter{section}{1}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[parfill]{parskip}

\begin{document}
\title{Sheldon Axler - Linear Algebra Done Right, 3rd edition - Chapter 2}
\author{Andrew Lim}

\def \problem#1{\subsubsection*{Problem #1}}
\def \real{\mathbf{R}}
\def \complex{\mathbf{C}}
\def \field{\mathbf{F}}

Notations are the same as what Axler uses. For example, we use boldface $\real$
for the reals, and $\field$ is $\real$ or $\complex$, not a general field.

\section{Finite-Dimensional Vector Spaces}

\subsection{Span and Linear Independence}

\problem{1}

Any $v \in V$ can be written as $a_1v_1 + a_2v_2 + a_3v_3 + a_4v_4$ for some
$a_i$. This in turn can be written as $a_1(v_1 - v_2) + (a_1 + a_2)(v_2 - v_3) +
(a_1 + a_2 + a_3)(v_3 - v_4) + (a_1 + a_2 + a_3 + a_4)v_4$. So this list also
spans $V$.

\problem{2a}

$\Rightarrow$: If $v = 0$, any nonzero choice of $a$ would satisfy $av = 0$,
violating linear independence. Thus $v \neq 0$.

$\Leftarrow$: $a = 0$ satifies $av = 0$. But $a \neq 0$ cannot, since we could
multiply both sides by $1/a$ to get $v = (1/a)0 = 0$, violating $v \neq 0$.

\problem{2b}

$\Rightarrow$: Call the vectors $v_1, v_2$. If one were a scalar multiple of the
other, say $v_2 = av_1$, then $(-a)v_1 + v_2 = 0$, violating linear
independence.

$\Leftarrow$: If the vectors were not linearly independent, then we could pick
$a_1v_1 + a_2v_2 = 0$, which we can rearrange to $v_2 = (-a_1/a_2)v_1$,
violating our assumption of no scalar multiples.

\problem{2c}

Any linear combination of these vectors $(a_1, a_2, a_3)$ is equal to $(a_1,
a_2, a_3, 0)$, which is only 0 if $a_1 = a_2 = a_3 = 0$. Thus, these are
linearly independent.

\problem{2d}

Any linear combination of these polynomials $(a_0, \ldots, a_m)$ is equal to
$a_0 + \ldots + a_mz^m$, which can only equal the additive identity polynomial
$0$ if each $a_i = 0$.

\problem{3}

A linear combination $a_1, a_2, a_3$ of these vectors equals $(3a_1 + 2a_2 +
5a_3, a_1 - 3a_2 + 9a_3, 4a_1 + 5a_2 + ta_3)$. For linear dependence, we want
there to be many solutions where this equals $(0,0,0)$.

The first two constraints give us $a_2 = 2a_3$. Substituting that into the sum
of the first two constraints, we get $4a_1 + 12a_3 = 0$; substituting into the
third constraint, we get $4a_1 + (10+t)a_3 = 0$. So $t = 2$ gives us many
possible solutions, since that makes these two constraints redundant, and
anything satisfying $a_2 = 2a_3$ and $a_1 = -3a_3$ will result in a linear
combination equaling $(0,0,0)$. For example, $a_1 = -3, a_2 = 2, a_3 = 1$ would
then result in $(0,0,0)$.

\problem{4}

$\Rightarrow$: Similar approach to problem 3. The constraints from the first two
elements, when added, give us $a_1 = -2a_3$. Substituting this into one of the
first two constraints gives $a_2 + 3a_3 = 0$; substituting this into the third
constraint gives us $2a_2 + (c-2)a_3 = 0$. These are identical for nonzero $a_i$
only if $c = 8$, so this is the only value for $c$ that can satisfy linear
dependence.

$\Leftarrow$: As per above, if $c = 8$, then any $a_1 = -2a_3$, $a_2 = -3a_3$
will create a linear combination equal to 0. For example, $(-2,-3,1)$ works.

\problem{5a}

Any linear combination equals $(a_1 + a_2) + (a_1 - a_2)i$. For this to equal 0,
$a_1 + a_2 = 0$ and $a_1 - a_2 = 0$, which is only possible if $a_1 = a_2 = 0$.

\problem{5b}

Any linear combination equals $(a_1 + a_2 - b_1 + b_2) + (a_1 - a_2 + b_1 +
b_2)i$. For this to equal 0, both of these groupings need to equal 0. Adding the
two constraints together yields $a_1 = -b_2$; substituting that in yields $a_2 =
b_1$. So any linear combination satisfying this would yield 0. For example,
$(1+i, 1-i)$ would work: $(1+i)^2 + (1-i)^2 = 0$.

\problem{6}

If they were not independent, there would exist $a_i$ not all zero such that
$a_1(v_1 - v_2) + a_2(v_2 - v_3) + a_3(v_3 - v_4) + a_4v_4 = 0$. Rearranging, we
get $a_1v_1 + (a_2 - a_1)v_2 + (a_3 - a_2)v_3 + (a_4 - a_3)v_4 = 0$.

Based on the first term, if $a_1 \neq 0$, we have a violation of the linear
independence of the $v_i$, so it must be that $a_1 = 0$. Moving to the next
term, for similar reasons, $a_2 = 0$, and then $a_3 = 0$. But then by the last
term we have $a_4 = 0$, which now violates the assumption that the $a_i$ are not
all zero. Hence, these vectors are independent.

\problem{7}

Suppose these were not linearly independent. Then there would exist $a_i$ not
all 0 such that $a_1(5v_1 - 4v_2) + a_2v_2 + \ldots + a_mv_m = 0$. Rearranging,
we get $5a_1v_1 + (a_2 - 4a_1)v_2 + \ldots + a_mv_m = 0$. By linear independence
of the $v_i$, it must be that $a_1 = 0$, then likewise $a_2 = 0$, and so on,
until we arrive at a contradiction because all the $a_i$ must be 0. Hence, these
vectors are also linearly independent.

\problem{8}

If these were not linearly independent, then some $a_i$ not all 0 would make
the sum of $\lambda a_iv_i$ equal 0. But then $\lambda a_i$ would also not all
be 0, violating the linear independence of the $v_i$. So the $\lambda v_i$ are
also linearly independent.

\problem{9}

Set $w_i = -v_i$. As proved in problem 8, if $v_i$ is linearly independent then
$w_i$ is as well, so any linearly independent $v_i$ will also gives us $w_i$
satisying the conditions of the statement. But $v_i + w_i = 0$ for all $i$, so
the sum is a list of 0s, which are not linearly independent.

\problem{10}

If $v_i + w$ are LD, then there exist $a_i$ not all 0 such that $\sum a_i(v_i +
w) = 0$. Rewrite this as $\sum a_iv_i + (\sum a_i)w = 0$. By LI of $v_i$, we
know that the first term cannot equal 0, and so likewise the second term cannot
equal 0, and therefore $\sum a_i \neq 0$ (if $w = 0$, then $v_i + w$ would
clearly not be LD). Thus we can move the second term to the right and divide by
$\sum a_i$ to get $w = \sum -(a_i / \sum a_i) v_i$, showing that $w \in
\text{span}(\{v_i\})$.

\problem{11}

$\Rightarrow$: If $w \in \text{span}(\{v_i\})$, then $\sum a_iv_i = w$ for some
$a_i$. Then $\sum a_iv_i - w = 0$. This violates the LI assumption, since we
have a linear combination of the $v_i$ and $w$ where at least one coefficient is
not zero (-1 on $w$). Therefore, $w \notin \text{span}(\{v_i\})$.

$\Leftarrow$: If $v_i$ and $w$ were not LI, then there would exist $a_i$ not all
0 such that $\sum a_iv_i + a_{m+1}w = 0$. For such $a_i$, it would not be
possible for $a_{m+1} = 0$, as then we would have $\sum a_iv_i = 0$ for $a_i$
not all 0, violating the assumption that the $v_i$ are LI. Thus, we could
rearrange to get $w = \sum (a_i/a_{m+1})v_i$, violating the assumption that $w
\notin \text{span}(\{v_i\})$. Therefore, $w \in \text{span}(\{v_i\})$.

\problem{12}

$\mathcal{P}_4(\field)$ is spanned by $(1, z, z^2, z^3, z^4)$. By 2.23, every LI
list of vectors can have at most 5 elements.

\problem{13}

In $\mathcal{P}_4(\field)$, $(1, z, z^2, z^3, z^4)$ are LI - to get any linear
combination of them to equal 0, you must multiply each of them by 0 itself.
By 2.23, a spanning list must then have length of at least 5.

\problem{14}

$\Rightarrow$: If $V$ is infinite-dimensional, no list spans $V$. We can
construct a required such sequence by starting with the empty list, which is LI,
then for $i = 1, 2, 3, \ldots$, picking $v_i$ such that it is not in the span of
the vectors before it, which is always possible since none of these lists can
span $V$.

$\Leftarrow$: Suppose $V$ were finite-dimensional. Then some list of vectors
spans it, and by 2.23, every LI list in $V$ must have length less than or equal
to the spanning list. But this is a contradiction, since we can create an LI
list of arbitrary length from our infinite sequence. Thus, $V$ is
infinite-dimensional.

\problem{15}

Consider the infinite sequence $\{v_i\}$, where $v_i$ has a 1 as its $i$th
element and 0 everywhere else. $v_1, \ldots, v_m$ is LI for any positive integer
$m$, since we cannot get the 0 sequence without multiplying each $v_i$ by 0. By
problem 14, $\field^\infty$ is infinite-dimensional.

\problem{16}

The infinite sequence of polynomials $1, z, z^2, \ldots$ defined over $[0, 1]$
is LI over its first $m$ elements for any positive integer $m$. By problem 14,
this vector space is infinite-dimensional.

\problem{17}

Each polynomial $p_j(z)$ can be written as $(z-2)(a_{j0} + \ldots +
a_{j(m-1)}z^{m-1})$ for some $a_{j0}, \ldots, a_{j(m-1)}$. Denote this
representation as $p_j(z) = (z-2)q_j(z)$.

To show that the $p_j$ are LD, we need to show that there exist $b_j$ not all 0
such that $\sum b_jp_j = 0$. This can be rewritten as $(z-2) \sum b_jq_j = 0$,
which implies that $\sum b_jq_j = 0$.

The $q_j$ are vectors in $\mathcal{P}_{m-1}(\field)$, which is itself a vector
space spanned by the list of $m$ polynomials $(1, z, \ldots, z^{m-1})$. By 2.23,
the $q_j$ must be LD, because they are a list of length $m+1$. Therefore, some
$b_j$ not all 0 exist such that $\sum b_jq_j = 0$, and thus also $\sum b_jp_j =
0$, making the $p_j$ LD.

\end{document}